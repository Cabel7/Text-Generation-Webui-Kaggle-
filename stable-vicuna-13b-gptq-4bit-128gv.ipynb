{
 "cells": [
   {
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://www.kaggle.com/code/ikaras/stable-vicuna-13b-gptq-4bit-128gv)"
      ]
    },
  {
   "cell_type": "markdown",
   "id": "b2ac1956",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# _**Text Generation Web UI**_\n",
    "\n",
    "# **_Model:_** <br>[**Stable-Vicuna-13b-GPTQ-4bit-128g**](https://huggingface.co/CarperAI/stable-vicuna-13b-delta)\n",
    "\n",
    "# **_License:_**\n",
    "**From https://vicuna.lmsys.org: The online demo is a research preview intended for non-commercial use only, subject to the model [License](https://github.com/facebookresearch/llama/blob/main/MODEL_CARD.md) of LLaMA, Terms of Use of the data generated by OpenAI, and Privacy Practices of ShareGPT. Please contact us If you find any potential violation. The code is released under the Apache License 2.0.\n",
    "gpt**\n",
    "\n",
    "# Note:\n",
    "1. **Don't try run the below code cell twice in the same runtime otherwise it might give you an error.** \n",
    "\n",
    "2. **Don't forget to turn on the GPU.**\n",
    "<br>\n",
    "\n",
    "**Special Thanks to [_Camenduru_](https://github.com/camenduru)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c915ee32",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mamba create -n textgen python=3.10.9 -y\n",
    "!/opt/conda/envs/textgen/bin/pip install google-api-python-client\n",
    "!sudo rm /opt/conda/bin/python3\n",
    "!sudo ln -sf /opt/conda/envs/textgen/bin/python3 /opt/conda/bin/python3\n",
    "!sudo rm /opt/conda/bin/python3.10\n",
    "!sudo ln -sf /opt/conda/envs/textgen/bin/python3 /opt/conda/bin/python3.10\n",
    "!sudo rm /opt/conda/bin/python\n",
    "!sudo ln -s /opt/conda/envs/textgen/bin/python3 /opt/conda/bin/python\n",
    "!python --version\n",
    "%cd /kaggle\n",
    "%env TF_CPP_MIN_LOG_LEVEL=/temp\n",
    "!apt -y update -qq\n",
    "!apt-get -y install -qq aria2\n",
    "!git clone -b v1.3 https://github.com/camenduru/text-generation-webui   \n",
    "%cd /kaggle/text-generation-webui\n",
    "!pip install -r requirements.txt\n",
    "!pip install -U gradio>=3.36.1\n",
    "!pip install ninja\n",
    "!mkdir /kaggle/text-generation-webui/repositories\n",
    "%cd /kaggle/text-generation-webui/repositories\n",
    "!git clone -b v1.2 https://github.com/camenduru/GPTQ-for-LLaMa.git\n",
    "%cd GPTQ-for-LLaMa\n",
    "!python setup_cuda.py install\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/4bit/stable-vicuna-13B-GPTQ/raw/main/config.json -d /kaggle/text-generation-webui/models/stable-vicuna-13B-GPTQ -o config.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/4bit/stable-vicuna-13B-GPTQ/raw/main/generation_config.json -d /kaggle/text-generation-webui/models/stable-vicuna-13B-GPTQ -o generation_config.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/4bit/stable-vicuna-13B-GPTQ/raw/main/special_tokens_map.json -d /kaggle/text-generation-webui/models/stable-vicuna-13B-GPTQ -o special_tokens_map.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/4bit/stable-vicuna-13B-GPTQ/resolve/main/tokenizer.model -d /kaggle/text-generation-webui/models/stable-vicuna-13B-GPTQ -o tokenizer.model\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/4bit/stable-vicuna-13B-GPTQ/raw/main/tokenizer_config.json -d /kaggle/text-generation-webui/models/stable-vicuna-13B-GPTQ -o tokenizer_config.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/4bit/stable-vicuna-13B-GPTQ/resolve/main/stable-vicuna-13B-GPTQ-4bit.compat.no-act-order.safetensors -d /kaggle/text-generation-webui/models/stable-vicuna-13B-GPTQ -o stable-vicuna-13B-GPTQ-4bit.compat.no-act-order.safetensors\n",
    "%cd /kaggle/text-generation-webui\n",
    "!python server.py --share --chat --wbits 4 --groupsize 128"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-07-15T07:33:03.037026",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
